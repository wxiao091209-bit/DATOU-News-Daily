#!/usr/bin/env python3
import os
import re
import json
import html
from datetime import datetime, timedelta
from urllib.parse import urljoin
import feedparser
import requests
from bs4 import BeautifulSoup

# ä¿åº•æ•°æ® - å½“RSSæŠ“å–å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨ï¼ˆé˜²æ­¢é¡µé¢ç©ºç™½ï¼‰
FALLBACK_DATA = {
    "summaries": [[
        {
            "text": "OpenAIå‘å¸ƒæ–°ä¸€ä»£æ¨¡å‹æ›´æ–°ï¼Œæå‡æ¨ç†èƒ½åŠ›ä¸å¤šæ¨¡æ€ç†è§£ï¼Œä¼ä¸šçº§APIåŒæ­¥ä¼˜åŒ–ã€‚",
            "source": "OpenAI Blog",
            "url": "https://openai.com/blog"
        },
        {
            "text": "Anthropicæ¨å‡ºClaudeæ–°åŠŸèƒ½ï¼Œæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡çª—å£ä¸ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚",
            "source": "Anthropic News", 
            "url": "https://www.anthropic.com/news"
        },
        {
            "text": "NVIDIAå‘å¸ƒæ–°ä¸€ä»£AIèŠ¯ç‰‡æ¶æ„ï¼Œæ¨ç†æ€§èƒ½æå‡æ˜¾è‘—ï¼Œäº‘æœåŠ¡å•†å·²åŒæ­¥ä¸Šçº¿ã€‚",
            "source": "NVIDIA Blog",
            "url": "https://blogs.nvidia.com"
        }
    ]],
    "categories": {
        "bigModel": {
            "title": "å¤§æ¨¡å‹",
            "desc": "GPT-5ã€Claude 4ã€Gemini Ultra ç­‰å‰æ²¿å¤§æ¨¡å‹æŠ€æœ¯çªç ´ä¸å•†ä¸šåŒ–è¿›å±•è¿½è¸ª",
            "icon": "M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z",
            "articles": [
                {"title": "OpenAI GPT-5æœ€æ–°æŠ€æœ¯è¿›å±•", "link": "https://openai.com/blog", "date": "", "summary": "OpenAIå‘å¸ƒæœ€æ–°æ¨¡å‹èƒ½åŠ›æ›´æ–°", "source": "OpenAI Blog", "readTime": "5 åˆ†é’Ÿ", "content": "<p>OpenAIæœ€æ–°åŠ¨æ€</p><p><a href='https://openai.com/blog' target='_blank'>æŸ¥çœ‹åŸæ–‡</a></p>"},
                {"title": "Anthropic Claude 4èƒ½åŠ›å‡çº§", "link": "https://www.anthropic.com/news", "date": "", "summary": "Claudeç³»åˆ—æ¨¡å‹æ–°åŠŸèƒ½å‘å¸ƒ", "source": "Anthropic News", "readTime": "4 åˆ†é’Ÿ", "content": "<p>Anthropicæœ€æ–°åŠ¨æ€</p><p><a href='https://www.anthropic.com/news' target='_blank'>æŸ¥çœ‹åŸæ–‡</a></p>"}
            ]
        },
        "hardware": {
            "title": "AI ç¡¬ä»¶",
            "desc": "ç®—åŠ›èŠ¯ç‰‡ã€æœºå™¨äººã€ç«¯ä¾§è®¾å¤‡ã€AI Phone ç­‰ç¡¬ä»¶è½½ä½“æŠ€æœ¯é©æ–°ä¸äº§ä¸šé“¾åŠ¨å‘",
            "icon": "M9 3v2m6-2v2M9 19v2m6-2v2M5 9H3m2 6H3m18-6h-2m2 6h-2M7 19h10a2 2 0 002-2V7a2 2 0 00-2-2H7a2 2 0 00-2 2v10a2 2 0 002 2zM9 9h6v6H9V9z",
            "articles": [
                {"title": "NVIDIAæ–°ä¸€ä»£AIèŠ¯ç‰‡å‘å¸ƒ", "link": "https://blogs.nvidia.com", "date": "", "summary": "GPUæ¶æ„å‡çº§ï¼Œæ¨ç†æ€§èƒ½æå‡", "source": "NVIDIA Blog", "readTime": "6 åˆ†é’Ÿ", "content": "<p>NVIDIAæœ€æ–°ç¡¬ä»¶åŠ¨æ€</p><p><a href='https://blogs.nvidia.com' target='_blank'>æŸ¥çœ‹åŸæ–‡</a></p>"}
            ]
        },
        "global": {
            "title": "å‡ºæµ·åŠ¨æ€",
            "desc": "ä¸­å›½ AI ä¼ä¸šå…¨çƒåŒ–å¸ƒå±€ã€æµ·å¤–ç›‘ç®¡æ”¿ç­–ã€è·¨å¢ƒæŠ•èèµ„ä¸æœ¬åœ°åŒ–æˆ˜ç•¥åˆ†æ",
            "icon": "M3.055 11H5a2 2 0 012 2v1a2 2 0 002 2 2 2 0 012 2v2.945M8 3.935V5.5A2.5 2.5 0 0010.5 8h.5a2 2 0 012 2 2 2 0 104 0 2 2 0 012-2h1.064M15 20.488V18a2 2 0 012-2h3.064M21 12a9 9 0 11-18 0 9 9 0 0118 0z",
            "articles": []
        },
        "investment": {
            "title": "æŠ•èèµ„",
            "desc": "ä¸€çº§å¸‚åœºèèµ„é€Ÿé€’ã€ç‹¬è§’å…½ä¼°å€¼å˜åŠ¨ã€IPO åŠ¨æ€ä¸èµ„æœ¬é£å‘è§£è¯»",
            "icon": "M12 8c-1.657 0-3 .895-3 2s1.343 2 3 2 3 .895 3 2-1.343 2-3 2m0-8c1.11 0 2.08.402 2.599 1M12 8V7m0 1v8m0 0v1m0-1c-1.11 0-2.08-.402-2.599-1M21 12a9 9 0 11-18 0 9 9 0 0118 0z",
            "articles": []
        },
        "industry": {
            "title": "äº§ä¸šè§‚å¯Ÿ",
            "desc": "è¡Œä¸šæ”¿ç­–è§£è¯»ã€ç«äº‰æ ¼å±€åˆ†æã€æŠ€æœ¯è¶‹åŠ¿é¢„æµ‹ä¸å•†ä¸šæ¨¡å¼æ¼”è¿›ç ”ç©¶",
            "icon": "M19 21V5a2 2 0 00-2-2H7a2 2 0 00-2 2v16m14 0h2m-2 0h-5m-9 0H3m2 0h5M9 7h1m-1 4h1m4-4h1m-1 4h1m-5 10v-5a1 1 0 011-1h2a1 1 0 011 1v5m-4 0h4",
            "articles": []
        },
        "product": {
            "title": "äº§å“å¿«è®¯",
            "desc": "AI åº”ç”¨æ–°å“å‘å¸ƒã€åŠŸèƒ½æ›´æ–°ã€ç”¨æˆ·ä½“éªŒä¼˜åŒ–ä¸å¸‚åœºåŒ–ç­–ç•¥è¿½è¸ªæŠ¥é“",
            "icon": "M13 10V3L4 14h7v7l9-11h-7z",
            "articles": []
        }
    }
}

# ä¸»è¦ä¿¡æºé…ç½®ï¼ˆåªä¿ç•™ç¨³å®šçš„è‹±æ–‡æºï¼‰
SOURCES = [
    {"name": "OpenAI Blog", "url": "https://openai.com/blog/rss.xml", "cat": "bigModel"},
    {"name": "Anthropic News", "url": "https://www.anthropic.com/news/rss.xml", "cat": "bigModel"},
    {"name": "Google DeepMind", "url": "https://deepmind.google/discover/feed/", "cat": "bigModel"},
    {"name": "Meta AI Blog", "url": "https://ai.meta.com/blog/rss/", "cat": "bigModel"},
    {"name": "NVIDIA Blog", "url": "https://blogs.nvidia.com/blog/category/artificial-intelligence/feed/", "cat": "hardware"},
    {"name": "TechCrunch AI", "url": "https://techcrunch.com/category/artificial-intelligence/feed/", "cat": "investment"},
    {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/topic/artificial-intelligence/feed", "cat": "industry"},
]

def fetch_rss_simple(url, name):
    """ç®€åŒ–ç‰ˆRSSæŠ“å–"""
    try:
        print(f"  æŠ“å–: {name}...")
        feed = feedparser.parse(url)
        
        if not feed.entries:
            print(f"    âš ï¸ {name} æ— æ•°æ®")
            return []
        
        entries = []
        for entry in feed.entries[:3]:
            summary = entry.get('summary', entry.get('description', ''))
            clean_summary = re.sub(r'<[^>]+>', '', summary)
            
            entries.append({
                "title": entry.title,
                "link": entry.link,
                "date": entry.get('published', ''),
                "summary": clean_summary[:150] + "..." if len(clean_summary) > 150 else clean_summary,
                "source": name,
                "readTime": "5 åˆ†é’Ÿ",
                "content": f"<p>{clean_summary[:200]}</p><p><a href='{entry.link}' target='_blank'>æŸ¥çœ‹åŸæ–‡ï¼š{name}</a></p>"
            })
        
        print(f"    âœ“ {name}: {len(entries)} æ¡")
        return entries
        
    except Exception as e:
        print(f"    âœ— {name}: å¤±è´¥")
        return []

def build_database():
    """æ„å»ºæ•°æ®åº“"""
    print("\nå¼€å§‹æŠ“å–æ•°æ®...")
    
    # åˆå§‹åŒ–æ•°æ®ç»“æ„
    database = {
        "summaries": [[]],
        "categories": {
            "bigModel": {"title": "å¤§æ¨¡å‹", "desc": "GPT-5ã€Claude 4ã€Gemini Ultra ç­‰å‰æ²¿å¤§æ¨¡å‹æŠ€æœ¯çªç ´ä¸å•†ä¸šåŒ–è¿›å±•è¿½è¸ª", "icon": "M9.75 17L9 20l-1 1h8l-1-1-.75-3M3 13h18M5 17h14a2 2 0 002-2V5a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z", "articles": []},
            "hardware": {"title": "AI ç¡¬ä»¶", "desc": "ç®—åŠ›èŠ¯ç‰‡ã€æœºå™¨äººã€ç«¯ä¾§è®¾å¤‡ã€AI Phone ç­‰ç¡¬ä»¶è½½ä½“æŠ€æœ¯é©æ–°ä¸äº§ä¸šé“¾åŠ¨å‘", "icon": "M9 3v2m6-2v2M9 19v2m6-2v2M5 9H3m2 6H3m18-6h-2m2 6h-2M7 19h10a2 2 0 002-2V7a2 2 0 00-2-2H7a2 2 0 00-2 2v10a2 2 0 002 2zM9 9h6v6H9V9z", "articles": []},
            "global": {"title": "å‡ºæµ·åŠ¨æ€", "desc": "ä¸­å›½ AI ä¼ä¸šå…¨çƒåŒ–å¸ƒå±€ã€æµ·å¤–ç›‘ç®¡æ”¿ç­–ã€è·¨å¢ƒæŠ•èèµ„ä¸æœ¬åœ°åŒ–æˆ˜ç•¥åˆ†æ", "icon": "M3.055 11H5a2 2 0 012 2v1a2 2 0 002 2 2 2 0 012 2v2.945M8 3.935V5.5A2.5 2.5 0 0010.5 8h.5a2 2 0 012 2 2 2 0 104 0 2 2 0 012-2h1.064M15 20.488V18a2 2 0 012-2h3.064M21 12a9 9 0 11-18 0 9 9 0 0118 0z", "articles": []},
            "investment": {"title": "æŠ•èèµ„", "desc": "ä¸€çº§å¸‚åœºèèµ„é€Ÿé€’ã€ç‹¬è§’å…½ä¼°å€¼å˜åŠ¨ã€IPO åŠ¨æ€ä¸èµ„æœ¬é£å‘è§£è¯»", "icon": "M12 8c-1.657 0-3 .895-3 2s1.343 2 3 2 3 .895 3 2-1.343 2-3 2m0-8c1.11 0 2.08.402 2.599 1M12 8V7m0 1v8m0 0v1m0-1c-1.11 0-2.08-.402-2.599-1M21 12a9 9 0 11-18 0 9 9 0 0118 0z", "articles": []},
            "industry": {"title": "äº§ä¸šè§‚å¯Ÿ", "desc": "è¡Œä¸šæ”¿ç­–è§£è¯»ã€ç«äº‰æ ¼å±€åˆ†æã€æŠ€æœ¯è¶‹åŠ¿é¢„æµ‹ä¸å•†ä¸šæ¨¡å¼æ¼”è¿›ç ”ç©¶", "icon": "M19 21V5a2 2 0 00-2-2H7a2 2 0 00-2 2v16m14 0h2m-2 0h-5m-9 0H3m2 0h5M9 7h1m-1 4h1m4-4h1m-1 4h1m-5 10v-5a1 1 0 011-1h2a1 1 0 011 1v5m-4 0h4", "articles": []},
            "product": {"title": "äº§å“å¿«è®¯", "desc": "AI åº”ç”¨æ–°å“å‘å¸ƒã€åŠŸèƒ½æ›´æ–°ã€ç”¨æˆ·ä½“éªŒä¼˜åŒ–ä¸å¸‚åœºåŒ–ç­–ç•¥è¿½è¸ªæŠ¥é“", "icon": "M13 10V3L4 14h7v7l9-11h-7z", "articles": []},
        }
    }
    
    all_articles = []
    
    # æŠ“å–å„æºæ•°æ®
    for source in SOURCES:
        entries = fetch_rss_simple(source['url'], source['name'])
        if entries:
            cat = source['cat']
            database['categories'][cat]['articles'].extend(entries)
            all_articles.extend(entries)
    
    # å¦‚æœæ²¡æœ‰æŠ“åˆ°ä»»ä½•æ•°æ®ï¼Œä½¿ç”¨ä¿åº•æ•°æ®
    if not all_articles:
        print("\nâš ï¸ æ‰€æœ‰RSSæºå¤±è´¥ï¼Œä½¿ç”¨ä¿åº•æ•°æ®")
        return FALLBACK_DATA
    
    # å»é‡
    for cat_key in database['categories']:
        articles = database['categories'][cat_key]['articles']
        seen = set()
        unique = []
        for a in articles:
            if a['link'] not in seen:
                seen.add(a['link'])
                unique.append(a)
        database['categories'][cat_key]['articles'] = unique[:6]
    
    # ç”Ÿæˆæ‘˜è¦
    summaries = []
    used_sources = set()
    for article in all_articles:
        if article['source'] not in used_sources:
            summaries.append({
                "text": article['summary'][:120] + "..." if len(article['summary']) > 120 else article['summary'],
                "source": article['source'],
                "url": article['link']
            })
            used_sources.add(article['source'])
        if len(summaries) >= 3:
            break
    
    database['summaries'] = [summaries]
    
    total = sum(len(v['articles']) for v in database['categories'].values())
    print(f"\nâœ“ æ€»è®¡: {total} ç¯‡æ–‡ç« ")
    
    return database

def update_html():
    """æ›´æ–°HTMLæ–‡ä»¶"""
    try:
        print("\næ­£åœ¨æ›´æ–° index.html...")
        
        with open('index.html', 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        new_db = build_database()
        json_str = json.dumps(new_db, ensure_ascii=False, indent=8)
        
        # æ›¿æ¢ contentDatabase
        pattern = r'const contentDatabase\s*=\s*\{[\s\S]*?\};'
        replacement = f'const contentDatabase = {json_str};'
        new_html = re.sub(pattern, replacement, html_content)
        
        # å¦‚æœæ­£åˆ™å¤±è´¥ï¼Œä½¿ç”¨å­—ç¬¦ä¸²æŸ¥æ‰¾
        if new_html == html_content:
            start_marker = 'const contentDatabase = {'
            start_idx = html_content.find(start_marker)
            if start_idx != -1:
                brace_count = 1
                i = start_idx + len(start_marker)
                while i < len(html_content) and brace_count > 0:
                    if html_content[i] == '{':
                        brace_count += 1
                    elif html_content[i] == '}':
                        brace_count -= 1
                    i += 1
                
                if brace_count == 0:
                    new_html = html_content[:start_idx] + f'const contentDatabase = {json_str};' + html_content[i:]
        
        with open('index.html', 'w', encoding='utf-8') as f:
            f.write(new_html)
        
        print("âœ“ æ›´æ–°æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— é”™è¯¯: {e}")
        return False

if __name__ == '__main__':
    print("ğŸ¤– DATOU AI News")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    update_html()
